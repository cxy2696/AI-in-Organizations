# This workflow installs Python dependencies, runs linting, tests, and (optionally) executes a Jupyter notebook.
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python

name: Python AI Tool CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:
    runs-on: macos-latest  # mac-specific needed
    strategy:
      matrix:
        python-version: [ "3.10", "3.11", "3.12" ]  # Test across versions for compatibility

    steps:
    - uses: actions/checkout@v5  # Updated to v5

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5  # Updated to v5 (latest stable as of Oct 2025)
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'  # Cache pip for faster runs

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 pytest pytest-cov nbconvert jupyter  # Added for notebook execution/testing
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi  # Install project deps (e.g., openai, gradio)

    - name: Lint with flake8
      run: |
        # Stop if syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # Warnings for complexity and line length (GitHub editor is 127 chars)
        flake8 . --count --max-complexity=10 --max-line-length=127 --statistics

    - name: Execute Jupyter Notebook (if present)
      if: matrix.python-version == '3.12'  # Run only on primary version to save time
      run: |
        # Convert and run notebook as script (assumes notebook is hw3_xc535.ipynb)
        jupyter nbconvert --to script hw3_xc535.ipynb
        python hw3_xc535.py  # Or use --execute for direct run, but script conversion for CI

    - name: Test with pytest
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}  # Use secret; mock if needed for tests
      run: |
        pytest --cov --cov-report=xml  # Added coverage for better insights

    - name: Upload test results
      if: always()  # Run even on failure
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ matrix.python-version }}
        path: coverage.xml  # Upload coverage report as artifact
